# -*- coding: utf-8 -*-
"""how-to-make-reports.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TwivVdUbavTO2aIWBBDlFEUPvF74PwU-

# How to make reports from transactional data

I will use https://www.kaggle.com/carrie1/ecommerce-data . If you want to play with it then download the data file and use the next cell to get the data into colab. Or upload it on your google drive and read it from there (google how to do it).
"""

#from google.colab import files
#files.upload()

import pandas as pd

df = pd.read_csv('drive/My Drive/data/ecommerce-data.zip',encoding = "cp1252")

df.head()

"""Look at missing values"""

df.isna().mean()

"""Let's fill these missing customer ids with something to have its sales in the report"""

df['CustomerID'].fillna(-999,inplace=True)

"""You can see transactions per user. Let's see what time period we have. But first convert text date to python date"""

df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'],format='%m/%d/%Y %H:%M')

df['InvoiceDate'].min()

df['InvoiceDate'].max()

"""It's about a year. Ok. Now we want to create a sales report by month.

# 1. Create a table with unique users

In the project you already have this table. And in real life there is always such a table in the database. But in this case we do not have it.
"""

user = df.groupby(['CustomerID'])['InvoiceDate'].min().reset_index()

user.head()

user.columns = ['CustomerID','reg_date']

user['reg_month'] = user['reg_date'].values.astype('datetime64[M]')

"""No worries). It's just the first link from google on "pandas how to get first day of month" https://stackoverflow.com/questions/45304531/extracting-the-first-day-of-month-of-a-datetime-type-column-in-pandas"""

user

"""# 2. Generate a table with each possible month for each user.

That is how you get records in your report then users are in churn. Look
"""

min_month = df['InvoiceDate'].values.astype('datetime64[M]').min()

max_month = df['InvoiceDate'].values.astype('datetime64[M]').max()

(min_month, max_month)

pd.date_range(min_month,max_month,freq='MS')

"""MS means start of the month, to get the first day of the month. 'M' gives the last day"""

dr = pd.DataFrame(pd.date_range(min_month,max_month,freq='MS'))

dr

dr.columns = ['month']

"""Now we have to perform cross join with user table and get"""

len(user)*len(dr)

"""rows. In pandas it could be performed like this"""

dr['key'] = 1
user['key'] = 1

report = dr.merge(user,on='key')

report.head()

len(report)

"""Like expected. But we have some extra rows: some users came long after minimal date (2010-12) and it's stupid to have records for a user before he came to us)."""

len(report[report['month']>=report['reg_month']])

report = report[report['month']>=report['reg_month']]

"""Let's look at some specific user"""

report[report['CustomerID'] == 12346.0]

report[report['CustomerID'] == 12448.0]

"""Now we can join sales information. But before doing it

# 3. Pre-aggregate transactional data before joining with report

I will calculate total sales for each month for each customer
"""

df.head()

df['month'] = df['InvoiceDate'].values.astype('datetime64[M]')

df['revenue'] = df['UnitPrice'] * df['Quantity']

sales_month = df.groupby(['CustomerID','month'])[['revenue']].agg(['sum']).reset_index()

sales_month.head()

sales_month.columns = ['CustomerID','month','revenue']

sales_month.head()

"""# 4. Join to report"""

report = report.merge(sales_month,how='left',on=['CustomerID','month'])

"""It is very important to use the left join! Using the left join we are keeping all rows from the report table -- that's how we understand gaps in customer activity."""

report.head()

"""Let's look at a particular customer"""

report[report['CustomerID'] == 12347.0]

"""We can see that his activity is not regular! For example there is pause in purchases after 2011-01-01 for two months. And then purchases start again.

# 5. Basic metrics

Add user, active, and new user counts
"""

report['user'] = 1
report['new'] = (report['reg_month'] == report['month']) * 1
report['active'] = (report['revenue'] > 0) * 1

report.head()

report.groupby('month')[['revenue','user','new','active']].agg('sum')

"""Add average revenue per customer"""

t = report.groupby('month')[['revenue','user','new','active']].agg('sum')

t['avg_revenue'] = t['revenue'] / t['active']

t

"""# 6. Churn

Same way you can calculate churn metrics, like number of customers who are inactive for 1,2,3,..,n months. Let's check all logic on this one customer (it's a good habit by the way to check your logic on one object and then scale it to the whole base)
"""

report[report['CustomerID'] == 12347.0]

"""For each customer I want to get a marker (or a flag) whether or not he was active in the previous month"""

report['active_prev'] = (report.sort_values(by=['month'], ascending=True)
                       .groupby(['CustomerID'])['active'].shift(1))

"""This hard stuff is something like a window function from sql. Because I have many customers I have to somehow say to pandas that they should be treated separately, so that's what groupby for. And also I want months to be in order, that's what sort_values for. Finally shift gives the value from the previous row (month in this case). Check it"""

report[report['CustomerID'] == 12347.0]

"""Correct. Compare the active column with active_prev. Now I want to understand when customer go from active to inactive and vice versa"""

report['change_status'] = (report['active'] != report['active_prev']) * 1

report[report['CustomerID'] == 12347.0]

"""Looks good. Next I want to assign some kind of id to each status change. And here is a very neat trick with cumulative sum. Look at the change_status column. If I perform a cumulative sum on this column I will get an increment each time the user changes status. That's what I want. And again I use this scary construction because I want pandas to treat each user separately."""

report['session_id'] = (report.sort_values(by=['month'], ascending=True)
                       .groupby(['CustomerID'])['change_status'].cumsum())

report[report['CustomerID'] == 12347.0]

"""It's perfect. Find a session with id 2. Can you see that it is the session where the user was inactive for two months? Now I can sum up the number of inactive months per user and per each session."""

report['inactive'] = (report['active'] == 0) * 1

report['month_inactive'] = (report.sort_values(by=['month'], ascending=True)
                       .groupby(['CustomerID','session_id'])['inactive'].cumsum())

"""Look at row number 4 (with index of 4067). In the month_inactive column we get the correct number of months the customer was inactive. Check it with your eyes. And it's correct for the whole table)."""

report[report['CustomerID'] == 12347.0]

"""Now let's calculate the metric. Say's number of users who has been in churn for two or more months"""

report['churn_2m'] = (report['month_inactive'] >= 2) * 1

report[report['CustomerID'] == 12347.0]

"""Looks good. Now groupby to get info for all customers per month"""

t = report.groupby('month')[['revenue','user','new','active','churn_2m']].agg('sum')

t

"""You also may want to get it in %. Choice of denominator depends on your methodology of churn. Here I will just use current user count for each month. But it might be user count for the previous month or even for month-2, because we are measuring two month churn."""

t['churn_2m%'] = t['churn_2m'] / t['user']

t

"""In the project you can use this table to calculate revenue from tariffs information. Just add tariff column for each user and then join tariffs table and calculate revenue in new column

This is a very robust way to create all kinds of reports: daily, weekly, monthly. If you generate all possible dates you will miss nothing. But keep in mind that the operation of cross join is computationally expensive and better be done in some sql database. I have a video about it on my channel https://youtu.be/s2uA0CTAlH0
"""